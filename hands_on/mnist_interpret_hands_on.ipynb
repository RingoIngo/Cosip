{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imported\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"interprettensor/interprettensor\")\n",
    "sys.path.append(\"interprettensor/interprettensor/modules\")\n",
    "from modules.sequential import Sequential\n",
    "from modules.linear import Linear\n",
    "from modules.softmax import Softmax\n",
    "from modules.relu import Relu\n",
    "from modules.tanh import Tanh\n",
    "from modules.avgpool import AvgPool\n",
    "from modules.convolution import Convolution\n",
    "import modules.render as render\n",
    "from modules.utils import Utils, Summaries, plot_relevances\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "flags = tf.flags\n",
    "flags.DEFINE_integer(\"batch_size\", 200,'Number of steps to run trainer.')\n",
    "flags.DEFINE_string(\"data_dir\", 'data','Directory for storing data')\n",
    "flags.DEFINE_string(\"summaries_dir\", 'my_model_logs','Summaries directory')\n",
    "flags.DEFINE_boolean(\"relevance\", True,'Compute relevances')\n",
    "flags.DEFINE_string(\"checkpoint_dir\", 'mnist_linear_model','Checkpoint dir')\n",
    "FLAGS = flags.FLAGS\n",
    "\n",
    "from IPython.display import clear_output, Image, display, HTML\n",
    "from tensorflow.examples.tutorials.mnist import input_data #import input_data\n",
    "print('Imported')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_vars(sess):\n",
    "    saver = tf.train.Saver()\n",
    "    tf.global_variables_initializer().run()\n",
    "    ckpt = tf.train.get_checkpoint_state(FLAGS.checkpoint_dir)\n",
    "    try: \n",
    "        if ckpt and ckpt.model_checkpoint_path:\n",
    "            print('Reloading from -- '+FLAGS.checkpoint_dir+'/model.ckpt')\n",
    "            saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "        else:\n",
    "            tvars = np.load('mnist_linear_model/model.npy')\n",
    "            for ii in range(8): sess.run(tf.trainable_variables()[ii].assign(tvars[ii]))\n",
    "            print('Reloading from numpy array!')\n",
    "    except:\n",
    "        raise ValueError('Layer definition and model layers mismatch!')\n",
    "    return saver\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################################################\n",
    "'''\n",
    "This function creates the neural network with layer definitions\n",
    "Input: Images as tensors \n",
    "Output: 10-d tensor for each image\n",
    "'''\n",
    "#################################################################################\n",
    "def neural_network():\n",
    "    # Define the layers for your neural network \n",
    "    return Sequential([Linear(input_dim=784,output_dim=1296, act='relu', batch_size=FLAGS.batch_size),                    \n",
    "                     Linear(1296, act='relu'), \n",
    "                     Linear(1296, act='relu'),\n",
    "                     Linear(10),\n",
    "                     Softmax()])\n",
    "    '''Fill your code here'''\n",
    "                   \n",
    "    return op\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data\\train-images-idx3-ubyte.gz\n",
      "Extracting data\\train-labels-idx1-ubyte.gz\n",
      "Extracting data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting data\\t10k-labels-idx1-ubyte.gz\n",
      "Forward Pass ... \n",
      "------------------------------------------------- \n",
      "linear_1:: "
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Tensor(\"Const_1:0\", shape=(), dtype=float32) must be from the same graph as Tensor(\"model/linear_1_1/Const:0\", shape=(), dtype=float32).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-9490392c86d3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvariable_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'model'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[0mmy_netowrk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mneural_network\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmy_netowrk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[1;31m#################################################################################\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Cosip\\hands_on\\interprettensor\\interprettensor\\modules\\sequential.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m     70\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'::'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m' '\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m                                                 \u001b[1;31m#print(X.get_shape().as_list())\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m             \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\n'\u001b[0m\u001b[1;33m+\u001b[0m \u001b[1;34m'------------------------------------------------- '\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Cosip\\hands_on\\interprettensor\\interprettensor\\modules\\linear.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input_tensor)\u001b[0m\n\u001b[0;32m     77\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmultiply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeep_prob\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 79\u001b[1;33m             \u001b[0mdropout_check\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeep_prob\u001b[0m\u001b[1;33m<=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1.0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     80\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m             \u001b[0mdropout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcond\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdropout_check\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdropout_check_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdropout_check_false\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda2\\envs\\cosip\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\u001b[0m in \u001b[0;36mless_equal\u001b[1;34m(x, y, name)\u001b[0m\n\u001b[0;32m   2144\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0m_ctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0min_graph_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2145\u001b[0m     _, _, _op = _op_def_lib._apply_op_helper(\n\u001b[1;32m-> 2146\u001b[1;33m         \"LessEqual\", x=x, y=y, name=name)\n\u001b[0m\u001b[0;32m   2147\u001b[0m     \u001b[0m_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2148\u001b[0m     \u001b[0m_inputs_flat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda2\\envs\\cosip\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[1;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[0;32m    348\u001b[0m       \u001b[1;31m# Need to flatten all the arguments into a list.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    349\u001b[0m       \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 350\u001b[1;33m       \u001b[0mg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_graph_from_inputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_Flatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeywords\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    351\u001b[0m       \u001b[1;31m# pylint: enable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    352\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mAssertionError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda2\\envs\\cosip\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_get_graph_from_inputs\u001b[1;34m(op_input_list, graph)\u001b[0m\n\u001b[0;32m   4634\u001b[0m         \u001b[0mgraph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph_element\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4635\u001b[0m       \u001b[1;32melif\u001b[0m \u001b[0moriginal_graph_element\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4636\u001b[1;33m         \u001b[0m_assert_same_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moriginal_graph_element\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgraph_element\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4637\u001b[0m       \u001b[1;32melif\u001b[0m \u001b[0mgraph_element\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mgraph\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4638\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"%s is not from the passed-in graph.\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mgraph_element\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda2\\envs\\cosip\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_assert_same_graph\u001b[1;34m(original_item, item)\u001b[0m\n\u001b[0;32m   4570\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0moriginal_item\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mitem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4571\u001b[0m     raise ValueError(\"%s must be from the same graph as %s.\" % (item,\n\u001b[1;32m-> 4572\u001b[1;33m                                                                 original_item))\n\u001b[0m\u001b[0;32m   4573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4574\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Tensor(\"Const_1:0\", shape=(), dtype=float32) must be from the same graph as Tensor(\"model/linear_1_1/Const:0\", shape=(), dtype=float32)."
     ]
    }
   ],
   "source": [
    "if tf.gfile.Exists(FLAGS.summaries_dir):\n",
    "    tf.gfile.DeleteRecursively(FLAGS.summaries_dir)\n",
    "tf.gfile.MakeDirs(FLAGS.summaries_dir)\n",
    "tf.reset_default_graph()\n",
    "\n",
    "#################################################################################\n",
    "'''\n",
    "Define the graph\n",
    "'''\n",
    "#################################################################################\n",
    "mnist = input_data.read_data_sets(FLAGS.data_dir, one_hot=True)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    x = tf.placeholder(tf.float32, [FLAGS.batch_size, 784], name='input')\n",
    "    with tf.variable_scope('model'):\n",
    "        my_netowrk = neural_network()\n",
    "        output = my_netowrk.forward(x)\n",
    "        \n",
    "        #################################################################################\n",
    "        '''Compute LRP'''\n",
    "        #################################################################################\n",
    "        RELEVANCE = '''Fill your code here'''\n",
    "\n",
    "    # Merge all the summaries and write them out \n",
    "    merged = tf.summary.merge_all()\n",
    "    test_writer = tf.summary.FileWriter(FLAGS.summaries_dir + '/my_model')\n",
    "\n",
    "    # Intialize variables and reload your model\n",
    "    saver = init_vars(sess)\n",
    "\n",
    "    # Extract testing data \n",
    "    xs, ys = mnist.test.next_batch(FLAGS.batch_size)\n",
    "    feed = {x:(2*xs)-1}\n",
    "    fetch = [merged, RELEVANCE]\n",
    "    #################################################################################\n",
    "    '''Run the session and fetch the relevances'''\n",
    "    #################################################################################\n",
    "    summary, relevance_test= '''Fill your code here'''\n",
    "    test_writer.add_summary(summary, 0)\n",
    "\n",
    "    # Save the images as heatmaps to visualize on tensorboard\n",
    "    images = xs.reshape([FLAGS.batch_size,28,28,1])\n",
    "    images = (images + 1)/2.0\n",
    "    plot_relevances(relevance_test.reshape([FLAGS.batch_size,28,28,1]), images, test_writer )\n",
    "\n",
    "    test_writer.close()\n",
    "    print('Completed plotting - Check Tensorboard')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
